<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
               "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Biomass validated events database protocols </title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="title" content="Biomass validated events database protocols "/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2017-06-08T16:31+1000"/>
<meta name="author" content="Ivan Hanigan"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  html { font-family: Times, serif; font-size: 12pt; }
  .title  { text-align: center; }
  .todo   { color: red; }
  .done   { color: green; }
  .tag    { background-color: #add8e6; font-weight:normal }
  .target { }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  {margin-left:auto; margin-right:0px;  text-align:right;}
  .left   {margin-left:0px;  margin-right:auto; text-align:left;}
  .center {margin-left:auto; margin-right:auto; text-align:center;}
  p.verse { margin-left: 3% }
  pre {
	border: 1pt solid #AEBDCC;
	background-color: #F3F5F7;
	padding: 5pt;
	font-family: courier, monospace;
        font-size: 90%;
        overflow:auto;
  }
  table { border-collapse: collapse; }
  td, th { vertical-align: top;  }
  th.right  { text-align:center;  }
  th.left   { text-align:center;   }
  th.center { text-align:center; }
  td.right  { text-align:right;  }
  td.left   { text-align:left;   }
  td.center { text-align:center; }
  dt { font-weight: bold; }
  div.figure { padding: 0.5em; }
  div.figure p { text-align: center; }
  div.inlinetask {
    padding:10px;
    border:2px solid gray;
    margin:10px;
    background: #ffffcc;
  }
  textarea { overflow-x: auto; }
  .linenr { font-size:smaller }
  .code-highlighted {background-color:#ffff00;}
  .org-info-js_info-navigation { border-style:none; }
  #org-info-js_console-label { font-size:10px; font-weight:bold;
                               white-space:nowrap; }
  .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                 font-weight:bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>

</head>
<body>

<div id="preamble">

</div>

<div id="content">
<h1 class="title">Biomass validated events database protocols </h1>


<hr/>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 Overview</a></li>
<li><a href="#sec-2">2 Johnston2011 Protocol:</a>
<ul>
<li><a href="#sec-2-1">2.1 References for the Johnston Protocol</a></li>
<li><a href="#sec-2-2">2.2 Detailed description of Johnston 2011 protocol</a></li>
</ul>
</li>
<li><a href="#sec-3">3 The Morgan 2010 Protocol</a></li>
<li><a href="#sec-4">4 The Salimi 2016 and 2017 Protocols</a></li>
<li><a href="#sec-5">5 The Bare Minimum Protocol</a></li>
<li><a href="#sec-6">6 Differential sampling intensity and potential exposure misclassification bias</a></li>
<li><a href="#sec-7">7 Data</a>
<ul>
<li><a href="#sec-7-1">7.1 Air pollution data provided</a></li>
<li><a href="#sec-7-2">7.2 Data derived</a></li>
</ul>
</li>
<li><a href="#sec-8">8 Selecting which of the protocols to follow</a></li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Overview</h2>
<div class="outline-text-2" id="text-1">


<p>
The database contains validated bushfire smoke events in Australian cities.
</p>
<p>
This page lists the available protocols for validating events. Feel free to create your own. Please do document it and upload it to the master database if you want to share data with us.
</p>
</div>

</div>

<div id="outline-container-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Johnston2011 Protocol:</h2>
<div class="outline-text-2" id="text-2">


<p>
This is the gold standard method and considerably more labour intensive than other methods.  
</p>
<p>
The Johnston Protocol was the first method our team developed for this project and was published as a peer reviewed journal article in 2011 (Johnston et al. 2011). This protocol is considered the most conceptually appealing and rigorous method. In this protocol, for each location the longest available time-series of daily smoke air pollution is acquired. In our original study there were up to 13 years (between 1994 and 2007) of daily air quality data measured as Particulate Matter (PM) less than 10 μm (PM10) or less than 2.5 μm (PM2.5) in aerodynamic diameter were examined. Air pollution data were provided by government agencies in the states of Western Australia, New South Wales, and Tasmania. Daily averages for each site were calculated excluding days with less than 75% of hourly measurements. In Sydney and Perth, where data were collected from several monitoring stations, the missing daily site-specific PM concentrations were imputed using available data from other proximate monitoring sites in the network. The daily city-wide PM concentrations were then estimated following the protocol of the Air Pollution and Health: a European Approach studies (Katsouyanni et al. 1996 and Atkinson et al. 2001).
</p>
<p>
First a ‘filling-in’ procedure was used to improve data completeness. It entailed the substitution of the missing daily values with a weighted average, using the weights of the missing sites 3-month average proportional to the network average. The weights are calculated against the values from the rest of the monitoring stations. The pollutant measures from all stations providing data were then averaged to provide single, city-wide estimates of the daily levels of the pollutants
</p>
<p>
For each city, all days in which PM10 or PM2.5 exceeded the 95th percentile were identified over the entire time series. These extreme values were termed ‘events’. A range of sources was examined to identify the cause of particulate air pollution events, including online news archives, Internet searches for other reports, government and research agencies, satellite imagery and a Dust Storms database. Satellite images were mostly sourced from NASA, but remotely sensed aerosol optical thickness (AOT) data were also examined, to provide further information about days for which the other methods did not.
</p>

</div>

<div id="outline-container-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> References for the Johnston Protocol</h3>
<div class="outline-text-3" id="text-2-1">

<p>The Johnston Protocol was used to initially develop the database. These are described in the paper Johnston, F. H., Hanigan, I. C., Henderson, S. B., Morgan, G. G., Portner, T., Williamson, G. J., &amp; Bowman, D. M. J. S. (2011). Creating an Integrated Historical Record of Extreme Particulate Air Pollution Events in Australian Cities from 1994 to 2007. Journal of the Air &amp; Waste Management Association, 61(4), 390–398. <a href="http://doi.org/10.3155/1047-3289.61.4.390">http://doi.org/10.3155/1047-3289.61.4.390</a>.
</p>
<p>
Atkinson, R.W., Anderson, R.H., Sunyer, J., Ayres, J., Baccini, M., Vonk, J.M., Boumghar, A., Forastiere, F., Forsberg, B., Touloumi, G., Schwartz, J. &amp; Katsouyanni, K. (2001). Acute Effects of Particulate Air Pollution on Respiratory Admissions. American Journal of Respiratory and Critical Care Medicine, 164(10), 1860–1866.
</p>
<p>
Katsouyanni, K., Schwartz, J., Spix, C., Touloumi, G., Zmirou, D., Zanobetti, A., Wojtyniak, B., Vonk, J.M., Tobias, A., Ponka, A., Medina, S., Bacharova, L. &amp; Anderson, H.R. (1996). Short term effects of air pollution on health: a European approach using epidemiologic time series data: the APHEA protocol. Journal of Epidemiology &amp; Community Health, 50(Suppl 1), S12–S18.
</p>
</div>

</div>

<div id="outline-container-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Detailed description of Johnston 2011 protocol</h3>
<div class="outline-text-3" id="text-2-2">

<p>Step 1: Air pollution data acquisition
</p>
<p>
Step 1.0 Time series observations of air pollution and spatial site location data were acquired from custodians.
</p>
<p>
Step 1.1. In an example, NSW data were downloaded from an online data server. Site locations (Latitude and Longitude) were obtained from the website.
</p>
<p>
Step 1.2. In a different example, WA data was sent on a CD from contacts at the WA Government Department, these were hourly data as provided. These were cleaned so as only days with &gt; 75% of hours available were used. Note that the license with WA Government places restrictions on our right to provide data to a third party. Therefore, those observed and imputed data were not included in the open access database, only the computed ‘potential events dates’.
</p>
<p>
Step 1.3. In a third example, Tasmanian data were sent via email from our contact at the Government Department; these were daily data and required minimal data cleaning.
</p>
<p>
Step 1.4. All data were combined into a PostGIS database and exploratory data analysis conducted.
</p>
<p>
Step 2. Define spatial extent for cities
The cities and towns were selected based on the aims of the original study to investigate cardio-respiratory disease and air pollution from extreme biomass smoke events in Australian cities and towns. These were Albany, Albury, Armidale, Bathurst, Bunbury, Busselton, Geraldton, Gosford-Wyong, Hobart, Illawarra, Launceston, Newcastle, Perth, Sydney, Tamworth and Wagga Wagga.
The spatial extent of each city and town was devised by intersecting Australian Bureau of Statistics Statistical Local Areas (SLAs) from the various Census editions. These boundaries were selected to give the best possible representation of hospital admissions from the population.
Air pollution monitoring sites were then selected on the basis of their spatial proximity to these locations.
</p>
<p>
Step 3. Imputation to fill in gaps in the time-series and calculate a network average
In cities where data were collected from several monitoring stations, the missing daily site-specific PM concentrations were imputed using available data from other proximate monitoring sites in the network. The daily city-wide PM concentrations were then estimated following the protocol of the APHEA studies.
</p>
<p>
Step 3.1. Firstly, data preparation was necessary to find the minimum date that the series of continuous observations can be considered to start. In the Australian datasets the earliest initial observations could not be used because they were usually made only on one day per week, and only during a particular season or of poor quality due to teething problems with equipment and procedures. Then it was necessary to identify missing dates and get a list of the sites and periods to include – that is, with more than 70% of days having observations present over the time period (as defined after we assessed the minimum and maximum dates of the period).
</p>
<p>
Step 3.2. For each station a daily network average of all the other non-missing sites was calculated (i.e. an average of all stations except the focal station of that iteration in the loop).
</p>
<p>
Step 3.3. A three monthly seasonal mean was calculated of these non-missing stations. Then a three-month seasonal mean for the missing site was calculated. The missing value was replaced by the mean level of the remaining stations, multiplied by a factor equal to the ratio of the seasonal (centered three month) mean for the missing station, over the corresponding mean from the stations that were available on that particular day.
</p>
<p>
Step 3.4. All sites for city wide averages were joined to fill any missing days at the site-level with average of the days immediately before and after the missing days (but only when this was below a threshold of 5% of observations in the record for that site).
</p>
<p>
Step 3.5. The average of all sites was calculated per day to create a city-wide average per day.
</p>
<p>
Step 3.6. Any missing days were filled at the city-wide level with the average of before and after (if 
this was less than 5% of days).
</p>
<p>
Step 4. Validate events and identify the causes
In this stage of the procedure it was necessary to select any dates with PM10 or PM2.5 greater than the 95th percentile. Then the analyst manually validated these ‘potential event dates’ using the news archives, government reports, satellite images and other relevant source documents. The contributor entered the information for each event into the custom built data entry forms. For any events with references for multiple types of source, it is important to assess the likelihood of any single source being the dominant one. A final double-check of any remaining 99th percentile dates with no references was made as these are a high priority subset of ‘potential event dates’.
</p>
<p>
Step 5. Contributed pollution and validated events inserted to master database
In new data contributions the data were sent by email (or via GitHub pull request) to our data manager and (after quality assurance checks) these were inserted into the master database copy and uploaded as the next version of the database snapshot on GitHub.
</p>
</div>
</div>

</div>

<div id="outline-container-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> The Morgan 2010 Protocol</h2>
<div class="outline-text-2" id="text-3">


<p>
This protocol was developed by one of our colleagues and authors (Dr Morgan) for a study in Sydney, Australia.  The procedure is very similar to the Johnston 2011 Protocol in that the ‘potential event dates’ are identified as days with city-wide 24 hours average PM concentrations greater than the 99th percentile for the study period. These dates are then validated as either bushfires or fuel-reduction burns on or immediately prior to these days by checking newspaper archives and any other sources. The main differences are that the 99th percentile is only used (instead of 95th and 99th), event type search word terms are restricted to ‘bushfire’ or ‘fuel-reduction/prescribed burn’ (not extended to include ‘smog’, ‘dust’ or ‘haze’), and there was no systematic review of satellite images.
</p>
<p>
Reference: Morgan G, Sheppeard V, Khalaj B, Ayyar A, Lincoln D, Jalaludin B, Beard J, Corbett S, Lumley T: Effects of bushfire smoke on daily mortality and hospital admissions in Sydney, Australia. Epidemiology 2010, 21(1):47-55.
</p>
</div>

</div>

<div id="outline-container-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> The Salimi 2016 and 2017 Protocols</h2>
<div class="outline-text-2" id="text-4">

<p>In 2016 one of our colleagues and authors (Dr Salimi) extended the biomass smoke database for Sydney. That project developed a refinement of the Johnston 2011 Protocol in which only satellite images and news archives were used. In the Salimi 2016 Protocol the air pollution data was processed in the same way as the Johnston Protocol.  In 2017 Dr Salimi applied these techniques to the city of Melbourne, Australia and in addition to satellite and news data on the same day and days prior, evidence was sought in searches of the government Environmental Protection Agency (EPA) reports.
</p>

</div>

</div>

<div id="outline-container-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> The Bare Minimum Protocol</h2>
<div class="outline-text-2" id="text-5">



<p>
In this protocol all that is required for an event to be validated is any reference that the contributor deems relevant. It is desirable that they add as much detail as possible to the database (e.g. author, title, publisher, year, URL, and date accessed).  To date only two references have been inserted using this protocol  [17, 18], but considering the greater ease with which contributors may validate events in this way it is envisaged that this protocol will prove popular. It is envisaged that this method will allow the database to capture more events in an opportunistic way as many sources of information will become available in an ad hoc fashion.  
</p>
<p>
However, this method is the least conceptually appealing because it results in a collection of events from times and places that have had unequal amounts of research effort expended on finding evidence (e.g. differential sampling intensity), and therefore may contain systematic biases and data that are not 'missing at random'.
</p>
</div>

</div>

<div id="outline-container-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Differential sampling intensity and potential exposure misclassification bias</h2>
<div class="outline-text-2" id="text-6">

<p>The Event Validation Protocols described in this paper are all conceptually appealing because they allow a collection of events from times and places if evidence is available from the sources.  Unfortunately the end result of combining these data into a single database is that the derived dataset is made up of components which have had unequal amounts of research effort expended on finding evidence (e.g. differential sampling intensity), as well as different search criteria used for finding the references to support events, and therefore the database may contain systematic biases and data that are not 'missing at random'.  
</p>

<p>
Epidemiological studies that investigate the relationship between health and air pollution exposures have primarily used time-series methods that study variations of some health outcomes such as deaths or hospitalizations from specific disease groups. These outcomes are usually monitored at a daily time resolution across whole cities, and relationships with atmospheric variables are estimated using regression models. Studies typically focus on daily levels of ambient air pollution measured by a network of monitoring sites scattered across a city, time matched to the health outcomes on the same day or a few days after.
</p>
<p>
This raises the potential for bias by exposure miss-classification, which would occur by classifying actual fire smoke/dust days as non-fire smoke/dust days, or classifying non-fire dust days as actual fire/dust days.  The impact of exposure misclassification will of course be related to the particular study design implemented with the fire smoke database. For time series studies the issue is discussed briefly in Morgan et al. 2010.  They explain that missing some bushfire days would reduce the power of the analysis to find an effect (if one is present), but it would be unlikely to bias the result. Because fire smoke/dust incidents are rare and PM is usual relatively low in Sydney (and in most other Australian cities) it is possible to categorize any day as having either “Biomass Smoke Event” PM or “background” PM. Morgan et al. 2010 included this background PM explicitly in their model to capture differences with the Biomass Smoke Event days. It is possible such an approach will include a small number of extra bushfire days with days categorized as background days. Morgan et al argue that any such inclusions would be unlikely to influence the background PM results due to the large number of non-bushfire days in a multi-year study period. The sensitivity analysis they conducted did not categorize daily PM into bushfire PM and background PM. They found results similar to those reported for background PM. This suggests that including additional bushfire days with non-bushfire days in the background PM analysis would not bias their PM results.
</p>

</div>

</div>

<div id="outline-container-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> Data</h2>
<div class="outline-text-2" id="text-7">


</div>

<div id="outline-container-7-1" class="outline-3">
<h3 id="sec-7-1"><span class="section-number-3">7.1</span> Air pollution data provided</h3>
<div class="outline-text-3" id="text-7-1">

<p>The NSW Air pollution data are available as cleaned data in the database, and raw data can be downloaded from <a href="http://www.environment.nsw.gov.au/AQMS/search.htm">http://www.environment.nsw.gov.au/AQMS/search.htm</a>. The raw and cleaned WA data are under a restricted license, although the derived event data are included in the database as open access.  The raw Tasmanian data are available on request, and the cleaned data are published in the database.  Any future data contributions will be published under open licenses if possible.
</p>
</div>

</div>

<div id="outline-container-7-2" class="outline-3">
<h3 id="sec-7-2"><span class="section-number-3">7.2</span> Data derived</h3>
<div class="outline-text-3" id="text-7-2">


<p>
The data set supporting the results of this article are available in the repository from the website on Github. We have applied the license under Creative Commons - Attribution 4.0. This allows others to copy, distribute and create derivative works provided that they credit this document along with the original source documents of the validation protocol they used (unless they created their own criteria).
</p></div>
</div>

</div>

<div id="outline-container-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> Selecting which of the protocols to follow</h2>
<div class="outline-text-2" id="text-8">

<p>Any of the protocols defined above can be used, or the contributor can create their own. This flexibility to allow multiple approaches is a strength of this database, but also presents the users with some challenges.  On the one hand it is beneficial that decisions on the protocol to be used can be made based on the resources available that can be allocated to the effort. On the other hand this presents difficulty to select which protocol to follow.  
</p>
<p>
For example a research team can balance the costs and benefits of hiring a dedicated research assistant to search news archives versus how much it costs to just search satellite imagery. But it can be a challenge to the contributor to consider the implications of the different options and make the necessary comparisons required for a final judgement.  In addition, the fact that different validation protocols are inherent in different groups of validated events there is a potential for selection bias to be introduced by differential sampling intensity in certain locations and time periods compared to others.  This is discussed below in the section on limitations.
</p>


</div>
</div>
</div>

</body>
</html>
